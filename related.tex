% !TEX root = paper.tex
\section{Related work}

At first blush, this problem seems to be reminiscent of the problem of
generating tests for programs written as control-flow graphs, with the
goal of exercising each acyclic path in the program, if possible.
There have been a number of techniques in the literature for test
generation. Mostly notably, techniques such as \textit{concolic}
testing attempt to identify a series of test data that would force
program execution thorough different paths~\cite{dart, concolic}.  Other
approaches are based on model checking, with the goal of creating test
inputs to reach specific program states.

However, the problem of test generation from business rules is
different. Business rules do not describe the implementation of a
system: rather they only describe a model and many of the concerns
that arise when dealing with control flow graph derived from real code
are not pertinent.

\subsection{Model based testing}

The set of business rules can viewed as a model of an actual system
that supports them and our approach then becomes a variant of model
based test generation~\cite{utting2012}. Compared to the formalisms commonly used in the
literature our business rule language is more light weight. We do not
require the programmer to specify control flow properties or other
program level details.

Typical modeling languages used by model based testing systems include
UML sequence diagrams~\cite{nayak2009}, modeling specific languages
such as the Systems Modeling Language~\cite{friedenthal2011} and
finite state machine notations such as UML
state charts~\cite{offhut99}. While business rules as presented in this
paper could be expressed in any of these notations it would be
cumbersome and require some degree of non-trivial encoding on part of
the author, making it unattractive to a non-programmer. Our business
rule language is designed so that rules are written in much the same
way as one would write them in prose thereby making it more accessible
to non-programmers.

Sriganesh and Ramanathan~\cite{sriganesh2012} extract business rules
from systems described in the Business Process Model and Notation
language, a graphical notation used to describe business
processes. The rule output is in a format similar to our formalism and
our algorithm could conceivably be applied to generate test sequences
from these rules.

\subsection{AI Planning}

Previous work has applied AI planning to software
testing~\cite{Scheetz99ai,Howe97testcase}. The sequencing of
operations done by our algorithm is similar to the AI planning
problem~\cite{Weld94} where actions with pre- and postconditions are sequenced
by a planner algorithm using either forward or backward chaining. The
algorithms used by AI planners have been proven insufficient for the
size of models in our domain (backref).

Part of an AI planning problem is the initial state of the program,
including what objects exists and which conditions that can be
assumed. Our technique does not need this: The types of objects that
exist in the system are defined in the model along with operations
that create them. A test sequence will construct any object needed to
cover a given rule part.

Paradkar et al~\cite{conf/icws/ParadkarSWJOSL07}.\ presents a system
for testing web services specified in the semantic markup language
OWL-S. OWL-S represents operations in a manner similar to our language
with pre- and postcondtion. However each operation has only one
associated pre- and postcondition pair making it more akin to a rule
in our language. If one where to translate a model in our business
rule language into OWL-S each rule would have to be turned into a
standalone operation. Such a translation could potentially increase the
size of the search space and lead to spurious sequences being
reported. The focus of the technique presented in the paper is on
conformance testing, that is, testing if a given implementation
conforms to the specification. In our approach the business rules are
the specification and the aim is instead to generates tests that cover
all rules. The paper does not mention the size of the models the
technique was evaluated on or the size of the generated test
sequences.

\subsection{OO testing}
 ...
